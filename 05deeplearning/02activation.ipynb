{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6ZkQxq6MuHcu4yoOAwX8+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quantumseminar/textbook/blob/main/05deeplearning/02activation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 活性化関数\n",
        "\n",
        "これまで単にたし合わせてきた出力値を非線形性と言ってより複雑な関数に変換するための関数を適用します。これを活性化関数（かっせいかかんすう）と言います。\n",
        "\n",
        "活性化関数にはさまざまな種類がありますが、今回はよく利用されるReLUと呼ばれる活性化関数を適用します。これは、出力が0以下の場合には0となり、0以上の場合には、y=xとなる関数です。\n",
        "\n",
        "![../img/activation01.jpg](../img/activation01.jpg)\n",
        "\n",
        "この活性化関数は出力値に適用します。\n",
        "\n",
        "![../img/activation02.jpg](../img/activation02.jpg)\n",
        "\n",
        "単一のユニットで実行してみます。yを求めた後に、max関数を利用して、ReLUを表現してみます。\n"
      ],
      "metadata": {
        "id": "HWqY4emajU4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = 2\n",
        "w = 3\n",
        "b = 4\n",
        "\n",
        "y = w*x + b\n",
        "\n",
        "#こちらを挿入\n",
        "ya = max(0, y)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOwdsusNq8EB",
        "outputId": "48693ff4-d32e-43c8-be12-3bf8f8bd2ced"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "この場合、出力値が10で正の値ですので、そのまま10が出てきました。同様のことをPyTorchでも行ってみます。\n",
        "\n",
        "PyTorchの場合、活性化関数の設定ができます。"
      ],
      "metadata": {
        "id": "XavKBKksrHyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ツールを読み込み\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#入力値xの個数を3に設定\n",
        "num_input = 1\n",
        "\n",
        "#ニューロンの数を2に変更\n",
        "num_neuron = 1\n",
        "\n",
        "#単体ユニットを作る\n",
        "fc = nn.Linear(num_input, num_neuron)\n",
        "\n",
        "#wとbを設定します。今回wは三つ設定します。\n",
        "fc.weight = nn.Parameter(torch.tensor([[3.]]))\n",
        "fc.bias = nn.Parameter(torch.tensor([4.]))\n",
        "\n",
        "#xを決める。今回は1,2,3の三つを入れます。\n",
        "x = torch.tensor([[2]], dtype=torch.float32)\n",
        "\n",
        "#yを計算する\n",
        "y = F.relu(fc(x))\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR7NzNmKrJmh",
        "outputId": "7af5a66e-cb47-484c-bb0b-39f8a3e67c98"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[10.]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "こちらも同様に10が得られました。"
      ],
      "metadata": {
        "id": "zwDm_0R0rPFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ディープニューラルネットワーク\n",
        "これまでの活性化関数を含む計算を複数レイヤー繋げて行うとディープニューラルネットワークができます。前のレイヤーの出力を次のレイヤーの入力として扱うことでレイヤーを複数作ることができます（図ではバイアスを省略しています）。\n",
        "\n",
        "![../img/deep01.jpg](../img/deep01.jpg)\n",
        "\n",
        "\n",
        "左の入力から右の出力まで順番に計算をしていきます。\n",
        "\n",
        "今回は少し書き方を変更してみます。 Sequentialを利用して、順番に書くことができます。"
      ],
      "metadata": {
        "id": "zEzV4F51rU1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ツールを読み込み\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(3, 2),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(2, 3),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(3, 1),\n",
        ")\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB1VmDNrrJ2r",
        "outputId": "5153a3a2-7566-4e52-a56e-2422cb0e953e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=3, out_features=2, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=2, out_features=3, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "レイヤーができました。weightは初期のランダムの設定です。実行してみます。"
      ],
      "metadata": {
        "id": "YJ6QWbXfr5Li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[2,3,4]], dtype=torch.float32)\n",
        "model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7EcrFFNr3If",
        "outputId": "f40f3d2c-a2f5-435f-acd2-0af20f0f28c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4302]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "計算ができました。weightを自分で書きたいときは、レイヤーの番号を指定してテンソルを書き直します。"
      ],
      "metadata": {
        "id": "hjLP0xrtr8uY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model[0].weight = nn.Parameter(torch.tensor([[3.,4.,5.],[3.,4.,5.]]))\n",
        "model[0].bias = nn.Parameter(torch.tensor([4.]))\n",
        "\n",
        "model[2].weight = nn.Parameter(torch.tensor([[3.,4.],[3.,4.],[3.,4.]]))\n",
        "model[2].bias = nn.Parameter(torch.tensor([4.]))\n",
        "\n",
        "model[4].weight = nn.Parameter(torch.tensor([[3.,3.,3.]]))\n",
        "model[4].bias = nn.Parameter(torch.tensor([4.]))"
      ],
      "metadata": {
        "id": "MXJRNbk7r7CF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[2,3,4]], dtype=torch.float32)\n",
        "model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeEaaee1r-Za",
        "outputId": "e1385047-254a-45c1-f63d-1354db818b4d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2686.]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "これでディープニューラルネットワークができましたが、毎回自分で値を書き込むのは大変なので、今後は学習を通じて値を自動的に計算をします。"
      ],
      "metadata": {
        "id": "njR-YI-SsBuI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 確率的勾配法\n",
        "ディープラーニングでは途中の重みを自分で入力するのは大変なので、入力データとそれに対応した正解データ（ラベル）を用意して、自動的に学習や訓練を行います。\n",
        "\n",
        "\n",
        "学習は、損失関数と呼ばれる関数を利用します。入力値から出力値を計算し、正解のデータとの誤差を損失関数で計算します。最終的には誤差が0に近づくように学習します。\n",
        "\n",
        "\n",
        "学習は損失関数を利用してそれをゼロになるように計算をしますが。その際には最適化を利用します。最適化は、値を少しずらしその微分係数を求めて、傾きと逆の方に値を少し更新します。そのようにして値をゼロに少しずつ近づけます。\n",
        "\n",
        "最初にモデルを作成します。"
      ],
      "metadata": {
        "id": "sT4lmvY5uW-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ツールを読み込み\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "#レイヤーを作る\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(3, 2),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(2, 3),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(3, 1),\n",
        ")"
      ],
      "metadata": {
        "id": "aIshp8TEr_vh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に最適化アルゴリズムを選択します。PyTorchには最初から使いやすいアルゴリズムが搭載されています。今回のタイトルにもある確率的勾配法 Stochastic Gradient Descentを利用します。lrはLearning Rateの略でここは適当に0.01に決めておきます。"
      ],
      "metadata": {
        "id": "piQO9bBMucwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#最適化アルゴリズム。今回はSGDを採用。\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "UVZIhqaXua7U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に今回の誤差を計算する損失関数を選びます。今回は平均二乗誤差 Mean Squared Error を選びます。損失関数も使いやすいライブラリがPyTorchに搭載されています。"
      ],
      "metadata": {
        "id": "Lkfnr2oSugTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#誤差関数。今回はMSE。\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "cFOif0C-uemU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "では、早速学習を始めてみます。入力データxは2,3,4とします。正解データは今回は適当にy=3.14とします。\n",
        "\n",
        "最適化を通じて重みwがx=2,3,4を入れた時に、y=3.14に近づくように計算されます。\n",
        "\n",
        "値の更新は少しずつ行われるので、100回計算します。"
      ],
      "metadata": {
        "id": "u2At7QzuuxE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#今回学びたいデータ。xが入力値。yが正解ラベル。\n",
        "x = torch.tensor([[2,3,4]], dtype=torch.float32)\n",
        "y = torch.tensor([[3.14]], dtype=torch.float32)\n",
        "\n",
        "#損失関数の値を格納するリスト\n",
        "history = []\n",
        "\n",
        "#モデルの学習\n",
        "model.train()\n",
        "\n",
        "#20回学習する\n",
        "for i in range(100):\n",
        "    model.zero_grad()\n",
        "\n",
        "    #計算した出力\n",
        "    outputs = model(x)\n",
        "\n",
        "    #lossの計算逆伝搬\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #誤差関数を格納\n",
        "    history.append(loss.item())"
      ],
      "metadata": {
        "id": "hkokcCNPuhvR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ループが終わると学習が済みます。modelの中のパラメータが更新されていますので、xを入れて出力値yを求めてみます。"
      ],
      "metadata": {
        "id": "ynYiguemu1-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVA-jnCuu0SS",
        "outputId": "967305bb-8d0e-4f78-b000-249dd404ef11"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.1400]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "きちんと出力値は3.14となっていました。途中過程の損失関数の値をリストに格納しましたので、その値の変遷を確認してみたいと思います。"
      ],
      "metadata": {
        "id": "sB-eT0HMu5Fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "NIkuaXl7u3Ta",
        "outputId": "d2208bd0-af29-477b-b379-05a409b0438c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "損失関数は最初誤差が大きかったですが、最終的に0に近づくのが確認できます。\n",
        "\n"
      ],
      "metadata": {
        "id": "Ntp-lSsNu8JM"
      }
    }
  ]
}